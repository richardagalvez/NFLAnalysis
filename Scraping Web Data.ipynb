{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who should you take in the NFL draft? - Webscrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning has had many impacts across multiple fields and industries in at least the past 10 years. In sports, statistics began playing a large role in team design and recruitment, especially after the success of the Oakland A's in the early 2000's using the methods outlined in the book and movie *Money Ball*. To read more about the use of statistics in Baseball, see [Sabremetrics in wikipedia](https://en.wikipedia.org/wiki/Sabermetrics).\n",
    "\n",
    "I happen to live under a rock, so I hadn't actually seen *Money Ball* until very recently on a flight-- and, wow, what an awesome movie! I was quite inspired after watching it and thought by this time probably all kinds of stats are being used to guide business and sports decisions in all major sports. I'm a huge AI and machine learning (intelligence) aficionado, and I've been a lifelong sufferer as a Miami Dolphins fan, so I decided why not check out some NFL datasets and see if one can make predictions on the success rate of certain players? Maybe the poor Dolphins could be better advised on who to draft."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, first thing we need is data. After looking around the web a bit, I found that http://www.pro-football-reference.com/ has some pretty easily accessible (and machine readable) table data available on the Combine resulst and also historic probowl data.\n",
    "\n",
    "So the question is pretty clear, could we predict, based on Combine metrics alone, which player, by position will most likely become a probowler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn import ensemble\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Save a nice dark grey as a variable\n",
    "almost_black = '#262626'\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I just import some libraries we need for the analysis plus redefine some defaults from matplotlib (using python in case you haven't realized!). The next thing we need is a list of probowlers and combine data per year. This can be accomplished by stripping the information off of the reference listed above. \n",
    "\n",
    "Of course being dirty web data, we have to do some cleaning! Below I do the following:\n",
    "\n",
    "* Certain players' names in the probowl list come with a '+' or '\\*' to designate special status (for example, MVP of game or secondary selection). We're trying to train on simply if they went to the probowl so we remove those. \n",
    "\n",
    "\n",
    "* Also, I modify the height from a feet-inches format to just inches.\n",
    "\n",
    "\n",
    "* Finally, drop the duplicates and also some irrelevant columns + save the dataframe as a csv for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probowlers = []\n",
    "\n",
    "df = pd.read_html('http://www.pro-football-reference.com/play-index/nfl-combine-results.cgi?request=1&year_min=2000&year_max=2000&height_min=65&height_max=82&weight_min=149&weight_max=375&pos=K&show=p&order_by=year_id')[0]\n",
    "\n",
    "# the 'range' of the range function is from range(first, last + 1).\n",
    "\n",
    "for year in range(2000,2016):\n",
    "    df1 = pd.read_html('http://www.pro-football-reference.com/play-index/nfl-combine-results.cgi?request=1&year_min=%s&year_max=%s&height_min=65&height_max=82&weight_min=149&weight_max=375&pos=QB&pos=WR&pos=TE&pos=RB&pos=FB&pos=OT&pos=OG&pos=C&show=p&order_by=year_id' % (year, year))[0]\n",
    "    df2 = pd.read_html('http://www.pro-football-reference.com/play-index/nfl-combine-results.cgi?request=1&year_min=%s&year_max=%s&height_min=65&height_max=82&weight_min=149&weight_max=375&pos=DE&pos=DT&pos=ILB&pos=OLB&pos=SS&pos=FS&pos=CB&show=p&order_by=year_id' % (year, year))[0]\n",
    "    df3 = pd.read_html('http://www.pro-football-reference.com/play-index/nfl-combine-results.cgi?request=1&year_min=%s&year_max=%s&height_min=65&height_max=82&weight_min=149&weight_max=375&pos=LS&pos=K&pos=P&show=p&order_by=year_id' % (year, year))[0]\n",
    "    df = pd.concat([df, df1, df2, df3], ignore_index=True)\n",
    "    probowlers += pd.read_html('http://www.pro-football-reference.com/years/%s/probowl.htm' % year)[0]['Unnamed: 1'].tolist()\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "probowlers = [s.replace('+', '').replace('*','').replace('%', '').replace('&', '') for s in probowlers]\n",
    "df_pb = pd.Series(probowlers)\n",
    "df_pb = df_pb.drop_duplicates()\n",
    "\n",
    "df['Probowl'] = pd.Series(np.zeros(len(df)))\n",
    "for k, p in df_pb.iteritems():\n",
    "    for l, row in df.iterrows():\n",
    "        if row['Player'] == p:\n",
    "            df['Probowl'][l] = 1.0\n",
    "            \n",
    "df = df.drop(df_qb[df_qb['Player']=='Player'].index)\n",
    "df['Height_inches'] = 12*df['Height'].str.extract('([0-9]+)-([0-9]*\\.?[0-9]+)')[0].astype(int) + df['Height'].str.extract('([0-9]+)-([0-9]*\\.?[0-9]+)')[1].astype(int)\n",
    "df = df.drop(['Height'], 1)\n",
    "            \n",
    "drop_columns = ['Rk', 'AV', 'College', 'Drafted (tm/rnd/yr)']\n",
    "df = df.drop(drop_columns,1)\n",
    "\n",
    "df.to_csv('/Users/richard/data/NFL.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the above cell will produce a csv file we can later analyze (see the other notebooks in this series for position by position analysis)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
